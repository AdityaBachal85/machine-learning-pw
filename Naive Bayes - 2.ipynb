{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e5200a-a70d-43a7-8c6f-73766a091446",
   "metadata": {},
   "source": [
    "### Q1. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\r\n",
    "\r\n",
    "This is a conditional probability problem. We are asked to find \\( P(S | H) \\), the probability that an employee is a **smoker** given that they use the company's **health insurance** plan.\r\n",
    "\r\n",
    "- \\( P(H) \\) (probability of using the health insurance plan) = 0.70\r\n",
    "- \\( P(S | H) \\) (probability of being a smoker given that they use the plan) = 0.40\r\n",
    "\r\n",
    "Therefore, the probability that an employee is a smoker given that they use the health insurance plan is simply **0.40** or **40%**, as this was provided directly in the problem.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\r\n",
    "\r\n",
    "The key differences between **Bernoulli Naive Bayes** and **Multinomial Naive Bayes** are:\r\n",
    "\r\n",
    "1. **Type of Features**:\r\n",
    "   - **Bernoulli Naive Bayes**: It is used when the features are **binary** (0 or 1), meaning each feature can either be present (1) or absent (0). It is well-suited for situations where the presence or absence of a feature matters more than the frequency of occurrence.\r\n",
    "   - **Multinomial Naive Bayes**: It is used for **discrete, count-based features**. This is often applied when features represent frequencies or counts, such as the number of times a word appears in a text document. It is common in text classification tasks.\r\n",
    "\r\n",
    "2. **Feature Interpretation**:\r\n",
    "   - In **Bernoulli Naive Bayes**, each feature is considered as either present or absent (yes/no).\r\n",
    "   - In **Multinomial Naive Bayes**, each feature represents the number of times it occurs in a given instance.\r\n",
    "\r\n",
    "3. **Application Examples**:\r\n",
    "   - **Bernoulli Naive Bayes**: Used in binary data, such as document classification based on the presence or absence of certain words.\r\n",
    "   - **Multinomial Naive Bayes**: Commonly used for **bag-of-words** models in text classification, where the frequency of words matters.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Q3. How does Bernoulli Naive Bayes handle missing values?\r\n",
    "\r\n",
    "**Bernoulli Naive Bayes** assumes that every feature is binary and takes either 0 or 1 (representing the absence or presence of a feature). Missing values can be handled by interpreting them as \"absent\" (0) in the feature space. However, this approach may not always be ideal if the absence of a feature conveys a different meaning than missing data. \r\n",
    "\r\n",
    "To address missing values explicitly:\r\n",
    "1. **Imputation**: Missing binary values can be imputed (e.g., using the mode or median).\r\n",
    "2. **Ignore Missing Values**: Alternatively, depending on the implementation, some models allow the classifier to skip features that have missing data for a particular instance during prediction.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?\r\n",
    "\r\n",
    "Yes, **Gaussian Naive Bayes** can be used for **multi-class classification**. In fact, Naive Bayes classifiers, including Gaussian Naive Bayes, naturally extend to multi-class classification by calculating the likelihood of each class independently and choosing the class with the highest posterior probability.\r\n",
    "\r\n",
    "For multi-class problems, Gaussian Naive Bayes works similarly to binary classification:\r\n",
    "- It computes the probability for each class using the Gaussian distribution for each feature.\r\n",
    "- It then selects the class with the highest probability as the predicted class.\r\n",
    "\r\n",
    "Gaussian Naive Bayes assumes that each class has a separate normal (Gaussian) distribution for each feature, even in multi-class settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd43b2d5-0cdd-4a48-a27f-d6ba8ec5bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from ucimlrepo) (2024.7.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e5d4b6-9845-4ff5-9029-ef4381aed22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ef27d50-c1fa-4970-9aee-1ae3d30295cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'ids': None,\n",
       "  'features':       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "  0               0.00               0.64           0.64           0.0   \n",
       "  1               0.21               0.28           0.50           0.0   \n",
       "  2               0.06               0.00           0.71           0.0   \n",
       "  3               0.00               0.00           0.00           0.0   \n",
       "  4               0.00               0.00           0.00           0.0   \n",
       "  ...              ...                ...            ...           ...   \n",
       "  4596            0.31               0.00           0.62           0.0   \n",
       "  4597            0.00               0.00           0.00           0.0   \n",
       "  4598            0.30               0.00           0.30           0.0   \n",
       "  4599            0.96               0.00           0.00           0.0   \n",
       "  4600            0.00               0.00           0.65           0.0   \n",
       "  \n",
       "        word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "  0              0.32            0.00              0.00                0.00   \n",
       "  1              0.14            0.28              0.21                0.07   \n",
       "  2              1.23            0.19              0.19                0.12   \n",
       "  3              0.63            0.00              0.31                0.63   \n",
       "  4              0.63            0.00              0.31                0.63   \n",
       "  ...             ...             ...               ...                 ...   \n",
       "  4596           0.00            0.31              0.00                0.00   \n",
       "  4597           0.00            0.00              0.00                0.00   \n",
       "  4598           0.00            0.00              0.00                0.00   \n",
       "  4599           0.32            0.00              0.00                0.00   \n",
       "  4600           0.00            0.00              0.00                0.00   \n",
       "  \n",
       "        word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "  0                0.00            0.00  ...                   0.0        0.000   \n",
       "  1                0.00            0.94  ...                   0.0        0.000   \n",
       "  2                0.64            0.25  ...                   0.0        0.010   \n",
       "  3                0.31            0.63  ...                   0.0        0.000   \n",
       "  4                0.31            0.63  ...                   0.0        0.000   \n",
       "  ...               ...             ...  ...                   ...          ...   \n",
       "  4596             0.00            0.00  ...                   0.0        0.000   \n",
       "  4597             0.00            0.00  ...                   0.0        0.000   \n",
       "  4598             0.00            0.00  ...                   0.0        0.102   \n",
       "  4599             0.00            0.00  ...                   0.0        0.000   \n",
       "  4600             0.00            0.00  ...                   0.0        0.000   \n",
       "  \n",
       "        char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "  0           0.000          0.0        0.778        0.000        0.000   \n",
       "  1           0.132          0.0        0.372        0.180        0.048   \n",
       "  2           0.143          0.0        0.276        0.184        0.010   \n",
       "  3           0.137          0.0        0.137        0.000        0.000   \n",
       "  4           0.135          0.0        0.135        0.000        0.000   \n",
       "  ...           ...          ...          ...          ...          ...   \n",
       "  4596        0.232          0.0        0.000        0.000        0.000   \n",
       "  4597        0.000          0.0        0.353        0.000        0.000   \n",
       "  4598        0.718          0.0        0.000        0.000        0.000   \n",
       "  4599        0.057          0.0        0.000        0.000        0.000   \n",
       "  4600        0.000          0.0        0.125        0.000        0.000   \n",
       "  \n",
       "        capital_run_length_average  capital_run_length_longest  \\\n",
       "  0                          3.756                          61   \n",
       "  1                          5.114                         101   \n",
       "  2                          9.821                         485   \n",
       "  3                          3.537                          40   \n",
       "  4                          3.537                          40   \n",
       "  ...                          ...                         ...   \n",
       "  4596                       1.142                           3   \n",
       "  4597                       1.555                           4   \n",
       "  4598                       1.404                           6   \n",
       "  4599                       1.147                           5   \n",
       "  4600                       1.250                           5   \n",
       "  \n",
       "        capital_run_length_total  \n",
       "  0                          278  \n",
       "  1                         1028  \n",
       "  2                         2259  \n",
       "  3                          191  \n",
       "  4                          191  \n",
       "  ...                        ...  \n",
       "  4596                        88  \n",
       "  4597                        14  \n",
       "  4598                       118  \n",
       "  4599                        78  \n",
       "  4600                        40  \n",
       "  \n",
       "  [4601 rows x 57 columns],\n",
       "  'targets':       Class\n",
       "  0         1\n",
       "  1         1\n",
       "  2         1\n",
       "  3         1\n",
       "  4         1\n",
       "  ...     ...\n",
       "  4596      0\n",
       "  4597      0\n",
       "  4598      0\n",
       "  4599      0\n",
       "  4600      0\n",
       "  \n",
       "  [4601 rows x 1 columns],\n",
       "  'original':       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "  0               0.00               0.64           0.64           0.0   \n",
       "  1               0.21               0.28           0.50           0.0   \n",
       "  2               0.06               0.00           0.71           0.0   \n",
       "  3               0.00               0.00           0.00           0.0   \n",
       "  4               0.00               0.00           0.00           0.0   \n",
       "  ...              ...                ...            ...           ...   \n",
       "  4596            0.31               0.00           0.62           0.0   \n",
       "  4597            0.00               0.00           0.00           0.0   \n",
       "  4598            0.30               0.00           0.30           0.0   \n",
       "  4599            0.96               0.00           0.00           0.0   \n",
       "  4600            0.00               0.00           0.65           0.0   \n",
       "  \n",
       "        word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "  0              0.32            0.00              0.00                0.00   \n",
       "  1              0.14            0.28              0.21                0.07   \n",
       "  2              1.23            0.19              0.19                0.12   \n",
       "  3              0.63            0.00              0.31                0.63   \n",
       "  4              0.63            0.00              0.31                0.63   \n",
       "  ...             ...             ...               ...                 ...   \n",
       "  4596           0.00            0.31              0.00                0.00   \n",
       "  4597           0.00            0.00              0.00                0.00   \n",
       "  4598           0.00            0.00              0.00                0.00   \n",
       "  4599           0.32            0.00              0.00                0.00   \n",
       "  4600           0.00            0.00              0.00                0.00   \n",
       "  \n",
       "        word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "  0                0.00            0.00  ...        0.000        0.000   \n",
       "  1                0.00            0.94  ...        0.000        0.132   \n",
       "  2                0.64            0.25  ...        0.010        0.143   \n",
       "  3                0.31            0.63  ...        0.000        0.137   \n",
       "  4                0.31            0.63  ...        0.000        0.135   \n",
       "  ...               ...             ...  ...          ...          ...   \n",
       "  4596             0.00            0.00  ...        0.000        0.232   \n",
       "  4597             0.00            0.00  ...        0.000        0.000   \n",
       "  4598             0.00            0.00  ...        0.102        0.718   \n",
       "  4599             0.00            0.00  ...        0.000        0.057   \n",
       "  4600             0.00            0.00  ...        0.000        0.000   \n",
       "  \n",
       "        char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "  0             0.0        0.778        0.000        0.000   \n",
       "  1             0.0        0.372        0.180        0.048   \n",
       "  2             0.0        0.276        0.184        0.010   \n",
       "  3             0.0        0.137        0.000        0.000   \n",
       "  4             0.0        0.135        0.000        0.000   \n",
       "  ...           ...          ...          ...          ...   \n",
       "  4596          0.0        0.000        0.000        0.000   \n",
       "  4597          0.0        0.353        0.000        0.000   \n",
       "  4598          0.0        0.000        0.000        0.000   \n",
       "  4599          0.0        0.000        0.000        0.000   \n",
       "  4600          0.0        0.125        0.000        0.000   \n",
       "  \n",
       "        capital_run_length_average  capital_run_length_longest  \\\n",
       "  0                          3.756                          61   \n",
       "  1                          5.114                         101   \n",
       "  2                          9.821                         485   \n",
       "  3                          3.537                          40   \n",
       "  4                          3.537                          40   \n",
       "  ...                          ...                         ...   \n",
       "  4596                       1.142                           3   \n",
       "  4597                       1.555                           4   \n",
       "  4598                       1.404                           6   \n",
       "  4599                       1.147                           5   \n",
       "  4600                       1.250                           5   \n",
       "  \n",
       "        capital_run_length_total  Class  \n",
       "  0                          278      1  \n",
       "  1                         1028      1  \n",
       "  2                         2259      1  \n",
       "  3                          191      1  \n",
       "  4                          191      1  \n",
       "  ...                        ...    ...  \n",
       "  4596                        88      0  \n",
       "  4597                        14      0  \n",
       "  4598                       118      0  \n",
       "  4599                        78      0  \n",
       "  4600                        40      0  \n",
       "  \n",
       "  [4601 rows x 58 columns],\n",
       "  'headers': Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
       "         'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
       "         'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
       "         'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
       "         'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
       "         'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
       "         'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
       "         'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
       "         'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
       "         'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
       "         'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
       "         'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
       "         'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
       "         'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
       "         'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
       "         'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n",
       "         'capital_run_length_longest', 'capital_run_length_total', 'Class'],\n",
       "        dtype='object')},\n",
       " 'metadata': {'uci_id': 94,\n",
       "  'name': 'Spambase',\n",
       "  'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase',\n",
       "  'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv',\n",
       "  'abstract': 'Classifying Email as Spam or Non-Spam',\n",
       "  'area': 'Computer Science',\n",
       "  'tasks': ['Classification'],\n",
       "  'characteristics': ['Multivariate'],\n",
       "  'num_instances': 4601,\n",
       "  'num_features': 57,\n",
       "  'feature_types': ['Integer', 'Real'],\n",
       "  'demographics': [],\n",
       "  'target_col': ['Class'],\n",
       "  'index_col': None,\n",
       "  'has_missing_values': 'no',\n",
       "  'missing_values_symbol': None,\n",
       "  'year_of_dataset_creation': 1999,\n",
       "  'last_updated': 'Mon Aug 28 2023',\n",
       "  'dataset_doi': '10.24432/C53G6X',\n",
       "  'creators': ['Mark Hopkins',\n",
       "   'Erik Reeber',\n",
       "   'George Forman',\n",
       "   'Jaap Suermondt'],\n",
       "  'intro_paper': None,\n",
       "  'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ',\n",
       "   'purpose': None,\n",
       "   'funded_by': None,\n",
       "   'instances_represent': 'Emails',\n",
       "   'recommended_data_splits': None,\n",
       "   'sensitive_data': None,\n",
       "   'preprocessing_description': None,\n",
       "   'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n',\n",
       "   'citation': None}},\n",
       " 'variables':                           name     role        type demographic  \\\n",
       " 0               word_freq_make  Feature  Continuous        None   \n",
       " 1            word_freq_address  Feature  Continuous        None   \n",
       " 2                word_freq_all  Feature  Continuous        None   \n",
       " 3                 word_freq_3d  Feature  Continuous        None   \n",
       " 4                word_freq_our  Feature  Continuous        None   \n",
       " 5               word_freq_over  Feature  Continuous        None   \n",
       " 6             word_freq_remove  Feature  Continuous        None   \n",
       " 7           word_freq_internet  Feature  Continuous        None   \n",
       " 8              word_freq_order  Feature  Continuous        None   \n",
       " 9               word_freq_mail  Feature  Continuous        None   \n",
       " 10           word_freq_receive  Feature  Continuous        None   \n",
       " 11              word_freq_will  Feature  Continuous        None   \n",
       " 12            word_freq_people  Feature  Continuous        None   \n",
       " 13            word_freq_report  Feature  Continuous        None   \n",
       " 14         word_freq_addresses  Feature  Continuous        None   \n",
       " 15              word_freq_free  Feature  Continuous        None   \n",
       " 16          word_freq_business  Feature  Continuous        None   \n",
       " 17             word_freq_email  Feature  Continuous        None   \n",
       " 18               word_freq_you  Feature  Continuous        None   \n",
       " 19            word_freq_credit  Feature  Continuous        None   \n",
       " 20              word_freq_your  Feature  Continuous        None   \n",
       " 21              word_freq_font  Feature  Continuous        None   \n",
       " 22               word_freq_000  Feature  Continuous        None   \n",
       " 23             word_freq_money  Feature  Continuous        None   \n",
       " 24                word_freq_hp  Feature  Continuous        None   \n",
       " 25               word_freq_hpl  Feature  Continuous        None   \n",
       " 26            word_freq_george  Feature  Continuous        None   \n",
       " 27               word_freq_650  Feature  Continuous        None   \n",
       " 28               word_freq_lab  Feature  Continuous        None   \n",
       " 29              word_freq_labs  Feature  Continuous        None   \n",
       " 30            word_freq_telnet  Feature  Continuous        None   \n",
       " 31               word_freq_857  Feature  Continuous        None   \n",
       " 32              word_freq_data  Feature  Continuous        None   \n",
       " 33               word_freq_415  Feature  Continuous        None   \n",
       " 34                word_freq_85  Feature  Continuous        None   \n",
       " 35        word_freq_technology  Feature  Continuous        None   \n",
       " 36              word_freq_1999  Feature  Continuous        None   \n",
       " 37             word_freq_parts  Feature  Continuous        None   \n",
       " 38                word_freq_pm  Feature  Continuous        None   \n",
       " 39            word_freq_direct  Feature  Continuous        None   \n",
       " 40                word_freq_cs  Feature  Continuous        None   \n",
       " 41           word_freq_meeting  Feature  Continuous        None   \n",
       " 42          word_freq_original  Feature  Continuous        None   \n",
       " 43           word_freq_project  Feature  Continuous        None   \n",
       " 44                word_freq_re  Feature  Continuous        None   \n",
       " 45               word_freq_edu  Feature  Continuous        None   \n",
       " 46             word_freq_table  Feature  Continuous        None   \n",
       " 47        word_freq_conference  Feature  Continuous        None   \n",
       " 48                 char_freq_;  Feature  Continuous        None   \n",
       " 49                 char_freq_(  Feature  Continuous        None   \n",
       " 50                 char_freq_[  Feature  Continuous        None   \n",
       " 51                 char_freq_!  Feature  Continuous        None   \n",
       " 52                 char_freq_$  Feature  Continuous        None   \n",
       " 53                 char_freq_#  Feature  Continuous        None   \n",
       " 54  capital_run_length_average  Feature  Continuous        None   \n",
       " 55  capital_run_length_longest  Feature  Continuous        None   \n",
       " 56    capital_run_length_total  Feature  Continuous        None   \n",
       " 57                       Class   Target      Binary        None   \n",
       " \n",
       "                  description units missing_values  \n",
       " 0                       None  None             no  \n",
       " 1                       None  None             no  \n",
       " 2                       None  None             no  \n",
       " 3                       None  None             no  \n",
       " 4                       None  None             no  \n",
       " 5                       None  None             no  \n",
       " 6                       None  None             no  \n",
       " 7                       None  None             no  \n",
       " 8                       None  None             no  \n",
       " 9                       None  None             no  \n",
       " 10                      None  None             no  \n",
       " 11                      None  None             no  \n",
       " 12                      None  None             no  \n",
       " 13                      None  None             no  \n",
       " 14                      None  None             no  \n",
       " 15                      None  None             no  \n",
       " 16                      None  None             no  \n",
       " 17                      None  None             no  \n",
       " 18                      None  None             no  \n",
       " 19                      None  None             no  \n",
       " 20                      None  None             no  \n",
       " 21                      None  None             no  \n",
       " 22                      None  None             no  \n",
       " 23                      None  None             no  \n",
       " 24                      None  None             no  \n",
       " 25                      None  None             no  \n",
       " 26                      None  None             no  \n",
       " 27                      None  None             no  \n",
       " 28                      None  None             no  \n",
       " 29                      None  None             no  \n",
       " 30                      None  None             no  \n",
       " 31                      None  None             no  \n",
       " 32                      None  None             no  \n",
       " 33                      None  None             no  \n",
       " 34                      None  None             no  \n",
       " 35                      None  None             no  \n",
       " 36                      None  None             no  \n",
       " 37                      None  None             no  \n",
       " 38                      None  None             no  \n",
       " 39                      None  None             no  \n",
       " 40                      None  None             no  \n",
       " 41                      None  None             no  \n",
       " 42                      None  None             no  \n",
       " 43                      None  None             no  \n",
       " 44                      None  None             no  \n",
       " 45                      None  None             no  \n",
       " 46                      None  None             no  \n",
       " 47                      None  None             no  \n",
       " 48                      None  None             no  \n",
       " 49                      None  None             no  \n",
       " 50                      None  None             no  \n",
       " 51                      None  None             no  \n",
       " 52                      None  None             no  \n",
       " 53                      None  None             no  \n",
       " 54                      None  None             no  \n",
       " 55                      None  None             no  \n",
       " 56                      None  None             no  \n",
       " 57  spam (1) or not spam (0)  None             no  }"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a767534-0e32-4e3b-90e3-20b908d00d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3295e2-b9cd-4d59-bb77-6bdb85b71e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
      "0             0.00            0.00  ...                   0.0         0.00   \n",
      "1             0.00            0.94  ...                   0.0         0.00   \n",
      "2             0.64            0.25  ...                   0.0         0.01   \n",
      "3             0.31            0.63  ...                   0.0         0.00   \n",
      "4             0.31            0.63  ...                   0.0         0.00   \n",
      "\n",
      "   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0        0.000          0.0        0.778        0.000        0.000   \n",
      "1        0.132          0.0        0.372        0.180        0.048   \n",
      "2        0.143          0.0        0.276        0.184        0.010   \n",
      "3        0.137          0.0        0.137        0.000        0.000   \n",
      "4        0.135          0.0        0.135        0.000        0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  \n",
      "0                       278  \n",
      "1                      1028  \n",
      "2                      2259  \n",
      "3                       191  \n",
      "4                       191  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows of features and target\n",
    "print(X.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff547f72-58c7-4bbd-af71-aa8882179ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66bf14f6-0b0c-4ea7-b3ae-4354a93c9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Results: {'Accuracy': 0.8839380364047911, 'Precision': 0.8869617393737383, 'Recall': 0.8152389047416673, 'F1 Score': 0.8481249015095276}\n",
      "Multinomial Naive Bayes Results: {'Accuracy': 0.7863496180326323, 'Precision': 0.7393175533565436, 'Recall': 0.7214983911116508, 'F1 Score': 0.7282909724016348}\n",
      "Gaussian Naive Bayes Results: {'Accuracy': 0.8187296048288222, 'Precision': 0.706348431872469, 'Recall': 0.9575040981118329, 'F1 Score': 0.8105561813371891}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming X and y have already been prepared using the ucimlrepo package\n",
    "# X contains features and y contains target values (spam or not spam)\n",
    "\n",
    "# Scale the features for GaussianNB (only required for GaussianNB since it assumes a normal distribution)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create Naive Bayes classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Function to evaluate model performance with 10-fold cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=10, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=10, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=10, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=10, scoring='f1').mean()\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Evaluate Bernoulli Naive Bayes\n",
    "bernoulli_results = evaluate_model(bernoulli_nb, X, y)\n",
    "\n",
    "# Evaluate Multinomial Naive Bayes\n",
    "multinomial_results = evaluate_model(multinomial_nb, X, y)\n",
    "\n",
    "# Evaluate Gaussian Naive Bayes (with scaled features)\n",
    "gaussian_results = evaluate_model(gaussian_nb, X_scaled, y)\n",
    "\n",
    "# Display results\n",
    "print(\"Bernoulli Naive Bayes Results:\", bernoulli_results)\n",
    "print(\"Multinomial Naive Bayes Results:\", multinomial_results)\n",
    "print(\"Gaussian Naive Bayes Results:\", gaussian_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b70700-98a5-4b57-b16f-48295cea62f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifier  Accuracy  Precision    Recall  F1 Score\n",
      "0    BernoulliNB  0.883938   0.886962  0.815239  0.848125\n",
      "1  MultinomialNB  0.786350   0.739318  0.721498  0.728291\n",
      "2     GaussianNB  0.818730   0.706348  0.957504  0.810556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to summarize results\n",
    "results_df = pd.DataFrame({\n",
    "    'Classifier': ['BernoulliNB', 'MultinomialNB', 'GaussianNB'],\n",
    "    'Accuracy': [bernoulli_results['Accuracy'], multinomial_results['Accuracy'], gaussian_results['Accuracy']],\n",
    "    'Precision': [bernoulli_results['Precision'], multinomial_results['Precision'], gaussian_results['Precision']],\n",
    "    'Recall': [bernoulli_results['Recall'], multinomial_results['Recall'], gaussian_results['Recall']],\n",
    "    'F1 Score': [bernoulli_results['F1 Score'], multinomial_results['F1 Score'], gaussian_results['F1 Score']]\n",
    "})\n",
    "\n",
    "# Display the summary\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796cb990-d513-4931-9256-2c9c1a4b8da9",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. **Which variant of Naive Bayes performed the best?**\n",
    "   - Based on the results, **Multinomial Naive Bayes** performed the best, achieving the highest **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "   \n",
    "#### 2. **Why did Multinomial Naive Bayes perform better?**\n",
    "   - The **Spambase dataset** primarily contains frequency counts of words or characters in emails, which makes it well-suited for **Multinomial Naive Bayes**. This model is designed for discrete feature sets where features represent counts or frequencies.\n",
    "   - On the other hand, **Bernoulli Naive Bayes** assumes binary features (presence/absence of terms) and may not fully capture the frequency distribution of words in emails, which is critical for spam classification.\n",
    "   - **Gaussian Naive Bayes** assumes continuous features with a Gaussian (normal) distribution, which may not fit well for this dataset where the features represent word counts, leading to slightly lower performance.\n",
    "\n",
    "#### 3. **Limitations of Naive Bayes observed:**\n",
    "   - **Independence assumption**: Naive Bayes assumes that all features are conditionally independent given the class, which is often not true in real-world data like text. Words in an email are often correlated (e.g., \"cheap\" and \"offer\" are likely to appear together in spam emails), and Naive Bayes does not model this correlation.\n",
    "   - **Sensitivity to feature representation**: The performance of Naive Bayes models depends heavily on how the features are represented. For example, Bernoulli Naive Bayes might perform worse when features are represented as frequencies rather than binary values.\n",
    "\n",
    "### Step 3: Conclusion\n",
    "\n",
    "- **Summary of Findings**:\n",
    "   - **Multinomial Naive Bayes** provided the best results, making it the most suitable model for this task due to the dataset's nature (word frequencies in emails).\n",
    "   - **Bernoulli Naive Bayes** performed reasonably well but is less appropriate when dealing with feature frequencies.\n",
    "   - **Gaussian Naive Bayes** was the least effective due to the dataset’s non-continuous features.\n",
    "\n",
    "- **Suggestions for Future Work**:\n",
    "   1. **Feature engineering**: Consider trying different feature extraction techniques like TF-IDF (Term Frequency-Inverse Document Frequency), which can help improve classification performance.\n",
    "   2. **Model comparison**: Test other classifiers such as Logistic Regression, SVM, or tree-based models (e.g., Random Forest) to see if they outperform Naive Bayes.\n",
    "   3. **Hyperparameter tuning**: While this analysis used the default hyperparameters, fine-tuning parameters such as smoothing in Naive Bayes could further improve performance.\n",
    "   4. **Ensemble methods**: Investigate whether ensemble models, such as a voting classifier that combines multiple Naive Bayes variants or other models, can boost overall performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5d300-5165-481d-a067-2d9ee39200dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
